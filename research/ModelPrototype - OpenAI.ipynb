{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI APIs initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(\n",
    "    temperature=0.9,\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source code download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "source_code = \"../source_code\"\n",
    "url = \"https://github.com/atikul-islam-sajib/ESRGAN\"\n",
    "\n",
    "Repo.clone_from(url=url, to_path=source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import warnings\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "from git import Repo\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.append(\"src/\")\n",
    "\n",
    "from utils import dump, load, config, CustomException\n",
    "from template import template\n",
    "\n",
    "\n",
    "class Explainer:\n",
    "    def __init__(self, url=None, model=\"OpenAI\"):\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "\n",
    "        self.CONFIG = config()\n",
    "\n",
    "    def access_api_key(self):\n",
    "        try:\n",
    "            self.OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "            return self.OPENAI_API_KEY\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise Exception(\"API key not found\")\n",
    "\n",
    "    def model_init(self):\n",
    "        if self.model == \"OpenAI\":\n",
    "            self.model = OpenAI(\n",
    "                temperature=self.CONFIG[\"OpenAI\"][\"temperature\"],\n",
    "                model_name=self.CONFIG[\"OpenAI\"][\"model_name\"],\n",
    "                openai_api_key=self.access_api_key(),\n",
    "            )\n",
    "\n",
    "            return self.model\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Model not found\".capitalize())\n",
    "\n",
    "    def download_source_code(self):\n",
    "        if os.path.exists(self.CONFIG[\"path\"][\"CODE_PATH\"]):\n",
    "            self.CODE_PATH = self.CONFIG[\"path\"][\"CODE_PATH\"]\n",
    "            self.URL = self.CONFIG[\"sourcecode\"][\"url\"]\n",
    "\n",
    "            try:\n",
    "                if self.URL:\n",
    "                    Repo.clone_from(url=self.URL, to_path=self.CODE_PATH)\n",
    "                else:\n",
    "                    raise CustomException(\"URL not found\".capitalize())\n",
    "\n",
    "            except CustomException as exception:\n",
    "                print(\"The exaceptio is\", exception)\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            os.makedirs(self.CONFIG[\"path\"][\"CODE_PATH\"], exist_ok=True)\n",
    "            print(\"Try it again to access further functionalities\".capitalize())\n",
    "\n",
    "    def generate_tokens(self):\n",
    "        self.extension = self.CONFIG[\"analysis\"][\"filenames\"]\n",
    "\n",
    "        try:\n",
    "\n",
    "            if (\n",
    "                self.extension == \"py\"\n",
    "                or self.extension == \"java\"\n",
    "                or self.extension == \"cpp\"\n",
    "            ):\n",
    "                self.loader = DirectoryLoader(\n",
    "                    path=os.path.join(\n",
    "                        self.CONFIG[\"path\"][\"CODE_PATH\"],\n",
    "                    ),\n",
    "                    glob=\"**/*.{}\".format(self.CONFIG[\"analysis\"][\"filenames\"]),\n",
    "                )\n",
    "\n",
    "                self.documents = self.loader.load()\n",
    "\n",
    "                return self.documents\n",
    "\n",
    "            else:\n",
    "                raise CustomException(\n",
    "                    \"File extension not found, check the config yaml file\".capitalize()\n",
    "                )\n",
    "\n",
    "        except CustomException as exception:\n",
    "            print(\"The exaceptio is\", exception)\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def database_init(self, documents=None):\n",
    "        self.database = self.CONFIG[\"vectorstores\"]\n",
    "\n",
    "        if isinstance(documents, list):\n",
    "            if self.database[\"Chroma\"]:\n",
    "                os.makedirs(\"./DB\", exist_ok=True)\n",
    "\n",
    "                self.vectordb = Chroma.from_documents(\n",
    "                    documents=documents,\n",
    "                    persist_directory=\"./DB\",\n",
    "                    embedding=OpenAIEmbeddings(),\n",
    "                )\n",
    "\n",
    "                print(\"Chroma is done\".capitalize())\n",
    "\n",
    "                return self.vectordb\n",
    "\n",
    "            else:\n",
    "                self.vectordb = FAISS.from_documents(\n",
    "                    documents=documents, embedding=OpenAIEmbeddings()\n",
    "                )\n",
    "\n",
    "                print(\"FAISS is done\".capitalize())\n",
    "\n",
    "                self.vectordb\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"documents must be a list\".capitalize())\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.CONFIG[\"chunks\"][\"chunk_size\"],\n",
    "            chunk_overlap=self.CONFIG[\"chunks\"][\"chunk_overlap\"],\n",
    "        )\n",
    "\n",
    "        self.documents = self.text_splitter.split_documents(\n",
    "            documents=self.generate_tokens()\n",
    "        )\n",
    "\n",
    "        dump(\n",
    "            value=self.documents,\n",
    "            filename=os.path.join(self.CONFIG[\"path\"][\"DATA_PATH\"], \"documents.pkl\"),\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"chunking is done and stored in the folder of {}\".format(\n",
    "                self.CONFIG[\"path\"][\"DATA_PATH\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return self.documents\n",
    "\n",
    "    def define_prompt_and_memeory(self):\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\", \"history\"], template=template\n",
    "        )\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            input_key=\"question\", memory_key=\"history\"\n",
    "        )\n",
    "\n",
    "        return {\"prompt\": self.prompt, \"memory\": self.memory}\n",
    "\n",
    "    def chatExplainer(self):\n",
    "        try:\n",
    "            self.vectordb = self.database_init(documents=self.generate_embeddings())\n",
    "        except ValueError as exception:\n",
    "            print(\"The exaceptio is\", exception)\n",
    "            traceback.print_exc()\n",
    "        except Exception as exception:\n",
    "            print(\"The exaceptio is\", exception)\n",
    "            traceback.print_exc()\n",
    "\n",
    "        self.retriever = self.vectordb.as_retriever()\n",
    "\n",
    "        self.chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.model_init(),\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.retriever,\n",
    "            chain_type_kwargs={\n",
    "                \"prompt\": self.define_prompt_and_memeory()[\"prompt\"],\n",
    "                \"memory\": self.define_prompt_and_memeory()[\"memory\"],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        self.chat_limit = self.CONFIG[\"chatExplainer\"][\"chat_limit\"]\n",
    "\n",
    "        while self.chat_limit > 0:\n",
    "            self.query = input(\"Query: \")\n",
    "            print(\"Answer: \", self.chain(self.query)[\"result\"])\n",
    "\n",
    "            self.chat_limit -= 1\n",
    "\n",
    "        print(\"The chat limit is completed. Try again !\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Explain the code\".capitalize())\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        type=str,\n",
    "        default=\"./config.yml\",\n",
    "        help=\"Define the config file\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\"--chat\", action=\"store_true\", help=\"Chat model\".capitalize())\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.config and args.chat:\n",
    "\n",
    "        explainer = Explainer()\n",
    "\n",
    "        explainer.download_source_code()\n",
    "        explainer.generate_tokens()\n",
    "\n",
    "        explainer.chatExplainer()\n",
    "\n",
    "    else:\n",
    "        print(\"The config file is not defined\".capitalize())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
